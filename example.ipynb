{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "848ad6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "import os\n",
    "import ft_ensemble\n",
    "import numpy as np\n",
    "import ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c150a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the pretrained models folder\n",
    "path_2_9km_models =   'pretrained_models/DenseSM_9km'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfdf954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162163\n",
      "159336\n"
     ]
    }
   ],
   "source": [
    "# path to training data CSV file\n",
    "input_fine = pd.read_csv('/mnt/data2tb/Transfer-DenseSM-E_pack/fusion/fusion_full.csv',index_col='s_index')\n",
    "print(len(input_fine))\n",
    "# Drop all rows where 'sm' (soil moisture) values are greater than 0.7 \n",
    "input_fine = input_fine[input_fine['sm'] <= 0.7]\n",
    "input_fine = input_fine[input_fine['sm'] > 0.0]\n",
    "print(len(input_fine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343294dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CHINA_100m', 'CHINA_1km', 'INDIA_100m', 'INDIA_1km', 'VN'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print names of sub dataset used for training\n",
    "np.unique(input_fine['network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17024aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = {'lr':4e-4, # learning rate\n",
    "        'epoch_Num':500,# number of epochs\n",
    "        'swa_start':40,\n",
    "        'alpha':0.7,# alpha in eq. 3\n",
    "        'beta':'auto',# beta in eq. 3 and was determined by eq.4\n",
    "        'domain_type':'coral',\n",
    "        'mv_type':'MAPE',\n",
    "        'ex':'ft12_models',\n",
    "        'batchS':1024,# size of batch\n",
    "        'br':1}# control the numbmer of unlabled samples and 9km samples, 1 means 1*batch_size\n",
    "network_name=['CHINA_100m', 'CHINA_1km', 'INDIA_100m', 'INDIA_1km', 'VN']\n",
    "base_dir = 'Demo' #%network_name\n",
    "model_dir_e = os.path.join(base_dir,setup['ex'])\n",
    "# if not os.path.exists(model_dir_e):\n",
    "#     os.mkdir(model_dir_e)\n",
    "os.makedirs(model_dir_e, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44604861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto\n"
     ]
    }
   ],
   "source": [
    "if isinstance(setup['beta'], str):\n",
    "    print(setup['beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01dd431",
   "metadata": {},
   "source": [
    "### Train with specific split ratio\n",
    "Chia bộ dữ liệu theo tỉ lệ train-val là 90/10. Bộ test sẽ sử dụng bộ dữ liệu Thái Bình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a235ab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143402\n",
      "15934\n",
      "Finetune sample: deletethis repeat: 0\n",
      "[-0.008  0.945  0.041  0.04   0.991]\n",
      "143402\n",
      "15934\n",
      "Finetune sample: deletethis repeat: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# name folder to save the models\n",
    "nsample = 'deletethis'\n",
    "model_dir = os.path.join(model_dir_e, '%s'%nsample)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# 3 is the number of repeats (we want 3 different set of models)\n",
    "for r in range(3):\n",
    "    if isinstance(setup['beta'], str):\n",
    "        model_dir_r = os.path.join(model_dir, 'a%s_b%s_r%s'%(int(setup['alpha']*100), setup['beta'], str(r)))\n",
    "    else:\n",
    "        model_dir_r = os.path.join(model_dir,'a%s_b%s_r%s'%(int(setup['alpha']*100),int(setup['beta']*100),str(r)))\n",
    "    if not os.path.exists(model_dir_r):\n",
    "        os.mkdir(model_dir_r)\n",
    "    s_index = input_fine.index.to_list()\n",
    "    \n",
    "    # Split the dataset into train and val set (9:1)\n",
    "    train_index, test_index = train_test_split(s_index, test_size=0.1, random_state=10, shuffle=True)\n",
    "\n",
    "    # Print the number of samples in train and test sets\n",
    "    print(len(train_index))\n",
    "    print(len(test_index))\n",
    "\n",
    "    # Prepare the training and validation data\n",
    "    train_val_index = [train_index, test_index]\n",
    "    trainloader, val_data, targetloader, train_data = utils.prepare_train_val_data_highres(input_fine, train_val_index, setup['batchS'], setup['br'])\n",
    "    \n",
    "    # Build the DenseSM models from the pretrained models\n",
    "    modelX = ft_ensemble.Build_DenseSM(path_2_9km_models)\n",
    "    modelX.rebuild_DenseSME()\n",
    "    data = {'sl': trainloader,\n",
    "            'tl':targetloader,\n",
    "            'cl':None,\n",
    "            'val_data': val_data,\n",
    "            'train_data':train_data}\n",
    "    \n",
    "    # Prepare the setup for finetuning\n",
    "    print(f'Finetune sample: {nsample} repeat: {r}')\n",
    "    ft = ft_ensemble.FinetuneModel(setup, data)\n",
    "    \n",
    "    # Finetuning the model\n",
    "    ft.ft_ensemble(modelX, model_dir_r)\n",
    "    df, res, m_specific_y=ft_ensemble.ensemble_results(model_dir_r, val_data)\n",
    "    res.scatter_density_fig(os.path.join(model_dir_r,'ensemble.jpg'))\n",
    "    print(res.stat_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cce50e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input_9km=utils.get_9km_of_a_network(input_fine,input_9km,network_name)\n",
    "# for nsample in size_r:\n",
    "#     model_dir = os.path.join(model_dir_e,'n_%s'%str(nsample))\n",
    "#     if not os.path.exists(model_dir):\n",
    "#         os.mkdir(model_dir)\n",
    "\n",
    "#     for r in range(10):# 10 implementation\n",
    "#         if isinstance(setup['beta'],str):\n",
    "#             model_dir_r = os.path.join(model_dir,'a%s_b%s_r%s'%(int(setup['alpha']*100),setup['beta'],str(r)))\n",
    "#         else:\n",
    "#             model_dir_r = os.path.join(model_dir,'a%s_b%s_r%s'%(int(setup['alpha']*100),int(setup['beta']*100),str(r)))\n",
    "#         if not os.path.exists(model_dir_r):\n",
    "#             os.mkdir(model_dir_r)\n",
    "#         train_val_index = utils.get_train_val_index(input_fine,nsample,network=network_name)\n",
    "#         trainloader, val_data,targetloader,train_data,loader_9km = utils.prepare_train_val_data_multiscale(input_fine,train_val_index,setup['batchS'],setup['br'])\n",
    "#         modelX=ft_ensemble.Build_DenseSM(path_2_9km_models)\n",
    "#         modelX.rebuild_DenseSME()\n",
    "#         data={'sl':trainloader,\n",
    "#              'tl':targetloader,\n",
    "#              'cl':loader_9km,\n",
    "#              'val_data':val_data,\n",
    "#              'train_data':train_data}\n",
    "#         print(f'Finetune sample:{nsample} repeat:{r}')\n",
    "#         ft=ft_ensemble.FinetuneModel(setup,data)\n",
    "#         ft.ft_ensemble(modelX,model_dir_r)\n",
    "#         df, res, m_specific_y=ft_ensemble.ensemble_results(model_dir_r, val_data)\n",
    "#         res.scatter_density_fig(os.path.join(model_dir_r,'ensemble.jpg'))\n",
    "#         print(res.stat_3d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soil_moisture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
