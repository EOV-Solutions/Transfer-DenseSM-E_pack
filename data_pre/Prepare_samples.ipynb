{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f823f82",
   "metadata": {},
   "source": [
    "## Prepare samples using GEE\n",
    "\n",
    "### Setup\n",
    "For each site, extract the full time series of Sentinel-1,NDVI data from the GEE. Note: if the output csv files already exist they are assumed to be correct and are not over-written.\n",
    "\n",
    "Note: Proxy was set for the well known reason in China and you may not need it. Also check the proxy in the utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bfa2765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import ee\n",
    "import utils_data_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22c06d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ee.Authenticate(force = True) # authenticate the gee account\n",
    "# ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892e463",
   "metadata": {},
   "source": [
    "Set the parameters, paths etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a9a802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DATA_DIR = '/mnt/data2tb/Transfer-DenseSM-E_pack/1km_global_data/india' # the dir of the region we want to get the data from \n",
    "# Date range for Sentinel-1 data\n",
    "START_DATE = \"2021-01-01\" #\"2016-01-01\" \n",
    "END_DATE =  \"2022-12-31\"  #\"2023-11-30\"  \n",
    "# Date range for NDVI and weather data,one year preceding the Sentinel-1\n",
    "START_DATE_NDVI = \"2019-12-26\" # Đáng lẽ là 2020-01-01, nhưng nới rộng thời gian thêm vài ngày để tránh bị miss     \n",
    "END_DATE_NDVI = \"2023-01-08\"  # Đáng lẽ là 2022-12-21, nhưng nới rộng thời gian thêm vài ngày để tránh bị miss \n",
    "#Global setups, dir, path\n",
    "save_to_disk = False # No temporal files\n",
    "SM_SITES = os.path.join(HOME_DATA_DIR, \"points/tree_grass_crops_site_info.csv\") # path to csv file of the site informaiton \n",
    "dir_to_site_sm = os.path.join(HOME_DATA_DIR, \"tree_grass_crops_csv_filtered\") # the path to the soil moisture of stations\n",
    "dir_to_site_samples = os.path.join(HOME_DATA_DIR, \"deletethis\") # the path to the output data\n",
    "os.makedirs(dir_to_site_samples, exist_ok= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e2f63e",
   "metadata": {},
   "source": [
    "Read the sites information and determine the grid size\n",
    "\n",
    "Note: Chú ý để thay đổi giá trị grid_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7f2da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the site information, includ the lat, lon, and the site name\n",
    "sites = pd.read_csv(SM_SITES, float_precision=\"high\")\n",
    "\n",
    "# if resolution = 1km, then the grid size = 1.0, if resolution = 100, then grid size = 0.1\n",
    "grid_size = 1.0 #km\n",
    "pobj=utils_data_pre.grids_4_a_region(4326,grid_size) # determine the grid size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9addc9",
   "metadata": {},
   "source": [
    "## A loop to prepare the input data of each site\n",
    "\n",
    "##### 1 Create the grid polygon covering a site in both EASE2.0 and WGS84\n",
    "##### 2 Extract Sentienl-1, soil texture, terrain, NDVI, precipition, temperature etc. Check the utils for the details\n",
    "##### 3 Concatenate all data\n",
    "##### 4 Extract the surface soil moisture of the site\n",
    "\n",
    "#### Note: \n",
    "* 'CHINA_100m': 100m dataset from Planet for the China's region.\n",
    "* 'CHINA_1km' : 1km dataset from NSIDC for the China's region.\n",
    "* 'INDIA_100m': 100m dataset from Planet for the India's region. \n",
    "* 'INDIA_1km' : 1km dataset from NSIDC for the India's region.\n",
    "* 'VN'        : 1km dataset from NSIDC for Vietnam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5da93a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>s_depth</th>\n",
       "      <th>e_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA_1km</td>\n",
       "      <td>1</td>\n",
       "      <td>28.068695</td>\n",
       "      <td>77.117534</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA_1km</td>\n",
       "      <td>2</td>\n",
       "      <td>28.056521</td>\n",
       "      <td>77.117582</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA_1km</td>\n",
       "      <td>3</td>\n",
       "      <td>28.034862</td>\n",
       "      <td>77.122390</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA_1km</td>\n",
       "      <td>7</td>\n",
       "      <td>27.966415</td>\n",
       "      <td>77.112073</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA_1km</td>\n",
       "      <td>8</td>\n",
       "      <td>27.954784</td>\n",
       "      <td>77.127043</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>INDIA_1km</td>\n",
       "      <td>646</td>\n",
       "      <td>27.696755</td>\n",
       "      <td>77.610797</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>INDIA_1km</td>\n",
       "      <td>647</td>\n",
       "      <td>27.682648</td>\n",
       "      <td>77.621828</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>INDIA_1km</td>\n",
       "      <td>648</td>\n",
       "      <td>27.672665</td>\n",
       "      <td>77.615471</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>INDIA_1km</td>\n",
       "      <td>649</td>\n",
       "      <td>27.642475</td>\n",
       "      <td>77.622366</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>INDIA_1km</td>\n",
       "      <td>650</td>\n",
       "      <td>27.626054</td>\n",
       "      <td>77.608647</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       network  station        lat        lon  s_depth  e_depth\n",
       "0    INDIA_1km        1  28.068695  77.117534        0        5\n",
       "1    INDIA_1km        2  28.056521  77.117582        0        5\n",
       "2    INDIA_1km        3  28.034862  77.122390        0        5\n",
       "3    INDIA_1km        7  27.966415  77.112073        0        5\n",
       "4    INDIA_1km        8  27.954784  77.127043        0        5\n",
       "..         ...      ...        ...        ...      ...      ...\n",
       "592  INDIA_1km      646  27.696755  77.610797        0        5\n",
       "593  INDIA_1km      647  27.682648  77.621828        0        5\n",
       "594  INDIA_1km      648  27.672665  77.615471        0        5\n",
       "595  INDIA_1km      649  27.642475  77.622366        0        5\n",
       "596  INDIA_1km      650  27.626054  77.608647        0        5\n",
       "\n",
       "[597 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites.columns\n",
    "filtered_sites = sites[sites['network'] == 'INDIA_1km'] # filter the sites by network\n",
    "filtered_sites.reset_index(drop = True, inplace=True)\n",
    "filtered_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef9d299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through each site to prepare the samples\n",
    "for i in range(len(sites)):\n",
    "    site = sites.loc[i]\n",
    "    print(f\"Processing for {i}: {site['station']}\")\n",
    "    # Create the path to save the samples\n",
    "    path_2_site_file = os.path.join(dir_to_site_samples,'%s.csv'%(site['network']+'_'+str(site['station'])))\n",
    "\n",
    "    # Check if the file already exists, if so, skip to the next site\n",
    "    if os.path.exists(path_2_site_file):\n",
    "        print(f\"{path_2_site_file} is already done.\")\n",
    "        continue\n",
    "\n",
    "    # Create the polygon grid covering the site in both EASE2.0 and WGS84\n",
    "    ring_wgs,grid_ring=pobj.get_wgs_grid(site.lon,site.lat)\n",
    "    polygon_grid=ee.Geometry.Polygon(ring_wgs, 'EPSG:4326', True, 20, False)\n",
    "\n",
    "    # Extract the samples for the site\n",
    "    samples,df_S1=utils_data_pre.samples_4_grid_v1(polygon_grid,START_DATE, END_DATE,START_DATE_NDVI,END_DATE_NDVI,ring_wgs,pobj, grid_size)\n",
    "    if df_S1 is None or samples is None:\n",
    "        print(\"Abort\")\n",
    "        continue\n",
    "\n",
    "    # include the ground truth of soil moisture\n",
    "    station_sm=pd.read_csv(os.path.join(dir_to_site_sm,'%s.csv'%(str(site['station']))),parse_dates=['time'])\n",
    "    sm_point=station_sm[station_sm.time.dt.date.isin(list(df_S1.date.dt.date))]['sm']\n",
    "\n",
    "    # Check if the length of sm_point matches the length of df_S1, we will get dates that are in df_S1\n",
    "    if len(sm_point) != len(df_S1):\n",
    "        print(f'Value and key do not have the same length, it is not a problem! {len(sm_point)} vs {len(df_S1)}')\n",
    "\n",
    "    sm_df = pd.DataFrame({'date': station_sm.time.dt.date, 'sm': sm_point})\n",
    "    sm_df['date'] = pd.to_datetime(sm_df['date'])\n",
    "    # Merge df_S1 with the soil moisture data, we will keep the dates that are in df_S1\n",
    "    df_S1 = df_S1.merge(sm_df, on = 'date', how = 'left')\n",
    "    # df_S1.loc[df_S1.date.dt.date.isin(list(station_sm.time.dt.date)),'sm_25']=list(sm_point)\n",
    "\n",
    "    # Concatenate the samples (NDVI, Temperature, Precipation. SoilGrids, DEM data) with df_S1 (Sentinel-1 data)\n",
    "    try:\n",
    "        samples=pd.DataFrame(samples,index=df_S1.index)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataFrame: {e}\")\n",
    "        print(f\"samples shape: {np.shape(samples)}\")\n",
    "        print(f\"df_S1 shape: {df_S1.shape}\")\n",
    "        continue\n",
    "    samples=pd.concat([df_S1,samples],axis=1)\n",
    "    samples.dropna(inplace = True)\n",
    "    samples.to_csv(path_2_site_file)\n",
    "    # Sleep for a while to avoid GEE errors\n",
    "    time.sleep(5)\n",
    "    print(\"Done !!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soil_moisture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
